---
title: "Beausejour, Jas - MovieLens Short Script"
author: "Jasmyn Beausejour"
date: "March 20, 2019"
output: html_document
---

This document is meant to be a supplement to the main report Beausejour, Jas - movieLens Report.Rmd.

It is a shorter version of the code, with much less nuance, aimed at quickly estimating the values and getting to our final RMSE.

In a way, this can be tought of as the piece of code that would be implemented in a real-life scenario.

**Step 1: Generating the datasets**

Here, we load a few required libraries.

```{r Loading libraries, message=FALSE, warning=FALSE, paged.print=FALSE}
if(!require(dslabs)) install.packages("dslabs", repos = "http://cran.us.r-project.org")
library(dslabs)

if(!require(tidyverse)) install.packages("tidyverse", repos = "http://cran.us.r-project.org")
library(tidyverse)

if(!require(knitr)) install.packages("knitr", repos = "http://cran.us.r-project.org")
library(knitr)

if(!require(kableExtra)) install.packages("kableExtra", repos = "http://cran.us.r-project.org")
library(kableExtra)
```

In the following code, we download the required files from the internet and create the edx, validation, test and train sets.

```{r Creating edx and validation, message=FALSE, warning=FALSE, include=FALSE, paged.print=FALSE}
if(!require(tidyverse)) install.packages("tidyverse", repos = "http://cran.us.r-project.org")
if(!require(caret)) install.packages("caret", repos = "http://cran.us.r-project.org")

# MovieLens 10M dataset:
# https://grouplens.org/datasets/movielens/10m/
# http://files.grouplens.org/datasets/movielens/ml-10m.zip

dl <- tempfile()
download.file("http://files.grouplens.org/datasets/movielens/ml-10m.zip", dl)

ratings <- read.table(text = gsub("::", "\t", readLines(unzip(dl, "ml-10M100K/ratings.dat"))),
                      col.names = c("userId", "movieId", "rating", "timestamp"))

movies <- str_split_fixed(readLines(unzip(dl, "ml-10M100K/movies.dat")), "\\::", 3)
colnames(movies) <- c("movieId", "title", "genres")
movies <- as.data.frame(movies) %>% mutate(movieId = as.numeric(levels(movieId))[movieId],
                                           title = as.character(title),
                                           genres = as.character(genres))

movielens <- left_join(ratings, movies, by = "movieId")

# Validation set will be 10% of MovieLens data

set.seed(1)
test_index <- createDataPartition(y = movielens$rating, times = 1, p = 0.1, list = FALSE)
edx <- movielens[-test_index,]
temp <- movielens[test_index,]

# Make sure userId and movieId in validation set are also in edx set

validation <- temp %>% 
     semi_join(edx, by = "movieId") %>%
     semi_join(edx, by = "userId")

# Add rows removed from validation set back into edx set

removed <- anti_join(temp, validation)
edx <- rbind(edx, removed)

rm(dl, ratings, movies, test_index, temp, movielens, removed)

# Test set will be 15% of edX data

set.seed(1)
test_index <- createDataPartition(y = edx$rating, times = 1, p = 0.15, list = FALSE)
train_set <- edx[-test_index,]
temp_set <- edx[test_index,]

# Make sure userId and movieId in test set are also in train set

test_set <- temp_set %>% 
     semi_join(train_set, by = "movieId") %>%
     semi_join(train_set, by = "userId")

# Add rows removed from test set set back into train set

removed_rows <- anti_join(temp_set, test_set)
train_set <- rbind(train_set, removed_rows)

rm(removed_rows, temp_set, test_index)

```

**Step 2: Creating the Regularized Movie Effect, with optimized Lambda**

As we know from the report, we are aiming for a model that looks like:

$$
Y_{u,i} = \mu + \hat{b}_i(\lambda_i) + \hat{b}_u(\lambda_u) + \varepsilon_{u,i}
$$

Here, $Y_{u,i}$ is the actual rating for a given movie, for a given user.  It is the product of $\mu$ the average rating in the dataset, $\hat{b}_i(\lambda_i)$ the regularized movie effect, $\hat{b}_u(\lambda_u)$ the regularized user-specific effect and $\varepsilon_{u,i}$ the residual.

Therefore, the first step is to get the optimized, regularized movie effect. See the long report for more details.

Note that here we are using our test set to perform tuning. This is not best practice, but since the final evaluation will be on the validation set, which we do not use here, we are comfortable doing so.

```{r}
# First, let's calculate mu

average_rating <- mean(train_set$rating)

# Second, let's cicle through a few lambdas to identify the optimal one

# This is the set of lambdas that we will be trying
lambdas <- seq(0, 10, 0.25)

mu <- mean(train_set$rating)
just_the_sum <- train_set %>% 
  group_by(movieId) %>% 
  summarize(s = sum(rating - mu), n_i = n())

#This is the loop to test the various lambdas and return RMSEs
rmses <- sapply(lambdas, function(l){
  predicted_ratings <- test_set %>% 
    left_join(just_the_sum, by='movieId') %>% 
    mutate(b_i = s/(n_i+l)) %>%
    mutate(pred = mu + b_i) %>%
    .$pred
  return(RMSE(predicted_ratings, test_set$rating))
})

# Third, we store our optimized lambda

lambda_movie <- lambdas[which.min(rmses)]

```

Our **lambda_movie** is

```{r}
lambda_movie
```


We now use this lambda to create our regularized movie effect in the following code:

```{r}
movie_reg_avgs <- train_set %>% 
  group_by(movieId) %>% 
  summarize(reg_movie_effects = sum(rating - average_rating)/(n()+lambda_movie), n_i = n()) 
```

**Step 3: Creating the Regularized User Effect, with optimized Lambda**

At this step, we repeat the previous analysis, but for the user effect, which takes into account both $\mu$ and the movie effect, $\hat{b}_i(\lambda_i)=\hat{b}_i(2)$. We are looking to create $\hat{b}_u(\lambda_u)$ while optimizing $(\lambda_u)$.

Note that here we are using our test set to perform tuning. This is not best practice, but since the final evaluation will be on the validation set, which we do not use here, we are comfortable doing so.

```{r best-lambdas}
# This is the set of lambdas that we will be trying
lambdas <- seq(0, 10, 0.25)

#This is the loop to test the various lambdas and return RMSEs
rmses <- sapply(lambdas, function(l){

  mu <- mean(train_set$rating)
  
  reg_b_i <- movie_reg_avgs %>% 
    group_by(movieId) %>%
    summarize(reg_b_i = reg_movie_effects)
  
  reg_b_u <- train_set %>% 
    left_join(reg_b_i, by="movieId") %>%
    group_by(userId) %>%
    summarize(reg_b_u = sum(rating - reg_b_i - mu)/(n()+l))

  predicted_ratings <- 
    test_set %>% 
    left_join(reg_b_i, by = "movieId") %>%
    left_join(reg_b_u, by = "userId") %>%
    mutate(pred = mu + reg_b_i + reg_b_u) %>%
    .$pred
  
    return(RMSE(predicted_ratings, test_set$rating))
})

# We store our optimized lambda

lambda_user <- lambdas[which.min(rmses)]
```

Our lambda user is

```{r}
lambda_user
```


Next, we compute our user effect table.

```{r}
user_reg_avg <- train_set %>% 
    left_join(movie_reg_avgs, by="movieId") %>%
    group_by(userId) %>%
    summarize(reg_user_effects = sum(rating - reg_movie_effects - average_rating)/(n()+lambda_user))
```

**Step 4: Make predictions**

We are now ready to use those tables to make prediction on our test set and see the resulting RMSE.

We start by creating our RMSE formula.

```{r Creating RMSE Formula}
RMSE <- function(true_ratings, predicted_ratings){
    sqrt(mean((true_ratings - predicted_ratings)^2))
  }
```

We then make the predictions.

```{r}

average_rating <- mean(edx$rating)

movie_reg_avgs <- edx %>% 
  group_by(movieId) %>% 
  summarize(reg_movie_effects = sum(rating - average_rating)/(n()+lambda_movie), n_i = n()) 

reg_b_i <- movie_reg_avgs %>% 
    group_by(movieId) %>%
    summarize(reg_b_i = reg_movie_effects)
  
reg_b_u <- edx %>% 
    left_join(reg_b_i, by="movieId") %>%
    group_by(userId) %>%
    summarize(reg_b_u = sum(rating - reg_b_i - mu)/(n()+lambda_user))

predicted_ratings <- 
    validation %>% 
    left_join(reg_b_i, by = "movieId") %>%
    left_join(reg_b_u, by = "userId") %>%
    mutate(pred = mu + reg_b_i + reg_b_u) %>%
    .$pred
```

And we calculate our final RMSE.

```{r}
finalRMSE <- RMSE(validation$rating,predicted_ratings)
```

As in our large report, **our final RMSE is**

```{r}
finalRMSE
```
This RMSE is worth 25/25 for purposes of grading.
